<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Using R for supervised learning &mdash; Duke NGS Course (Summer 2015) 1.0 documentation</title>
    
    <link rel="stylesheet" href="_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/bootstrap-3.2.0/css/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="_static/bootstrap-3.2.0/css/bootstrap-theme.min.css" type="text/css" />
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="_static/bootstrap-3.2.0/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="_static/bootstrap-sphinx.js"></script>
    <link rel="top" title="Duke NGS Course (Summer 2015) 1.0 documentation" href="index.html" />
    <link rel="next" title="Unsupervised Learning" href="UnsupervisedLearning.html" />
    <link rel="prev" title="Linear Regression" href="RFormulasAndStatisticalModeling.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body role="document">

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html">
          Duke NGS Course (Summer 2015)</a>
        <span class="navbar-text navbar-version pull-left"><b>1.0</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1"><a class="reference internal" href="VMsAtDuke.html">How to Claim and Access Your Virtual Machine</a></li>
<li class="toctree-l1"><a class="reference internal" href="BasicRinJupyterAndRstudio.html">Basic R in the Jupyter Notebook and RStudio</a></li>
<li class="toctree-l1"><a class="reference internal" href="IntroductionToR.html">Introduction to R</a></li>
<li class="toctree-l1"><a class="reference internal" href="PreparingDataForAnalysis.html">Preparing Data for Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="WorkingWithData.html">Working with Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="GroupingandAggregation.html">Grouping and Aggregation</a></li>
<li class="toctree-l1"><a class="reference internal" href="Hypothesistestingandpowercalcuations.html">Hypothesis Testing and Power Calculations</a></li>
<li class="toctree-l1"><a class="reference internal" href="Probabilitydistributionsandrandomnumbergeneration.html">Probability distributions and Random Number Genereation</a></li>
<li class="toctree-l1"><a class="reference internal" href="WritingcustomfunctionsinRSolutions.html">Writing Custom Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="FunctionalProgramming.html">Functional Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="RFormulasAndStatisticalModeling.html">Linear Regression</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="">Using R for supervised learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="UnsupervisedLearning.html">Unsupervised Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="UnsupervisedLearningAndNGS.html">Unsupervised Learning and NGS</a></li>
<li class="toctree-l1"><a class="reference internal" href="MultipleTesting.html">Multiple Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="CountModels.html">Counting Models/Discrete Distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="LogisticRegression.html">Generalized Linear Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="InstallPackages.html">Installing Graphics Packages</a></li>
<li class="toctree-l1"><a class="reference internal" href="BaseGraphics.html">Base Graphics</a></li>
<li class="toctree-l1"><a class="reference internal" href="MiscGraphics.html">Plotting Graphcs and Heatmpas</a></li>
<li class="toctree-l1"><a class="reference internal" href="BaseGraphicsGGPlotComparison.html">Introdcution to <code class="docutils literal"><span class="pre">ggplot2</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="GGPlot2Graphics.html">More <code class="docutils literal"><span class="pre">ggplot2</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="PracticeONESolutios.html">Coding Exercises</a></li>
<li class="toctree-l1"><a class="reference internal" href="DESeq2Notebook.html">Introduction to DESeq2</a></li>
<li class="toctree-l1"><a class="reference internal" href="Installation.html">Installing R, RStudio and IPython notebook with the R kernel</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Using R for supervised learning</a><ul>
<li><a class="reference internal" href="#supervised-learning-problem">Supervised learning problem</a><ul>
<li><a class="reference internal" href="#visualizing-the-data">Visualizing the data</a></li>
</ul>
</li>
<li><a class="reference internal" href="#comments">Comments</a><ul>
<li><a class="reference internal" href="#work">Work!</a></li>
<li><a class="reference internal" href="#splitting-data-into-training-and-test-data-sets">Splitting data into training and test data sets</a></li>
<li><a class="reference internal" href="#train-knn-on-training-set">Train knn on training set</a></li>
<li><a class="reference internal" href="#evaluate-the-model">Evaluate the model</a></li>
</ul>
</li>
<li><a class="reference internal" href="#who-was-predicted-wrongly">Who was predicted wrongly?</a><ul>
<li><a class="reference internal" href="#id1">Work!</a></li>
<li><a class="reference internal" href="#cross-validation">Cross-validation</a></li>
</ul>
</li>
<li><a class="reference internal" href="#loocv">LOOCV</a><ul>
<li><a class="reference internal" href="#id2">Work!</a></li>
<li><a class="reference internal" href="#supervised-learning-continued-what-could-go-wrong">Supervised Learning Continued - What Could Go Wrong?</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="RFormulasAndStatisticalModeling.html" title="Previous Chapter: Linear Regression"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; Linear Regres...</span>
    </a>
  </li>
  <li>
    <a href="UnsupervisedLearning.html" title="Next Chapter: Unsupervised Learning"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">Unsupervised ... &raquo;</span>
    </a>
  </li>
              
            
            
            
            
              <li class="hidden-sm">
<div id="sourcelink">
  <a href="_sources/SupervisedLearning.txt"
     rel="nofollow">Source</a>
</div></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12">
      
  <div class="section" id="using-r-for-supervised-learning">
<h1>Using R for supervised learning<a class="headerlink" href="#using-r-for-supervised-learning" title="Permalink to this headline">Â¶</a></h1>
<p>This notebook goes over the basic concept of how to construct and use a
supervised learning pipleine for classificaioon. We will use the
k-nearest neighbors algorithm for illustration, but the baisc ideas
carry over to all algorithms for classificaiton and regression.</p>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">healthdy</span> <span class="o">&lt;-</span> <span class="n">read</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="s">&#39;healthdy.txt&#39;</span><span class="p">,</span> <span class="n">header</span> <span class="o">=</span> <span class="n">TRUE</span><span class="p">)</span>
</pre></div>
</div>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">head</span><span class="p">(</span><span class="n">healthdy</span><span class="p">)</span>
</pre></div>
</div>
<table>
<thead><tr><th></th><th scope=col>ID</th><th scope=col>GENDER</th><th scope=col>FLEXPRE</th><th scope=col>FLEXPOS</th><th scope=col>BAWPRE</th><th scope=col>BAWPOS</th><th scope=col>BWWPRE</th><th scope=col>BWWPOS</th><th scope=col>BFPPRE</th><th scope=col>BFPPOS</th><th scope=col>FVCPRE</th><th scope=col>FVPOS</th><th scope=col>METSPRE</th><th scope=col>METSPOS</th></tr></thead>
<tbody>
    <tr><th scope=row>1</th><td>0</td><td>1</td><td>21.000</td><td>21.500</td><td>70.5</td><td>75.6</td><td>3.3</td><td>3.7</td><td>14.58</td><td>14.17</td><td>5.1</td><td>5.1</td><td>12.7</td><td>18.0</td></tr>
    <tr><th scope=row>2</th><td>2</td><td>1</td><td>21.000</td><td>21.250</td><td>71.3</td><td>70.7</td><td>3.2</td><td>3.6</td><td>16.79</td><td>13.95</td><td>4.3</td><td>4.3</td><td>11.1</td><td>12.0</td></tr>
    <tr><th scope=row>3</th><td>3</td><td>1</td><td>21.500</td><td>20.000</td><td>64.5</td><td>66.6</td><td>4.1</td><td>4.0</td><td>6.6</td><td>08.98</td><td>4.5</td><td>4.5</td><td>15.3</td><td>16.7</td></tr>
    <tr><th scope=row>4</th><td>4</td><td>1</td><td>23.000</td><td>23.375</td><td>97</td><td>95.0</td><td>4.4</td><td>4.3</td><td>18.04</td><td>17.32</td><td>4.7</td><td>4.3</td><td>12.0</td><td>17.5</td></tr>
    <tr><th scope=row>5</th><td>5</td><td>1</td><td>21.000</td><td>21.000</td><td>71</td><td>73.2</td><td>3.7</td><td>3.8</td><td>11.12</td><td>11.50</td><td>5.8</td><td>5.8</td><td>12.2</td><td>12.2</td></tr>
    <tr><th scope=row>6</th><td>6</td><td>1</td><td>20.500</td><td>20.750</td><td>72.5</td><td>73.1</td><td>3.1</td><td>3.4</td><td>17.88</td><td>16.22</td><td>4.3</td><td>4.3</td><td>11.1</td><td>10.0</td></tr>
</tbody>
</table><p>Data from Health Dynamics class at Hope College&#8211;collected about 1985 by Gregg Afman.
Downloaded from <a class="reference external" href="http://www.math.hope.edu/swanson/data/healthdy.txt">http://www.math.hope.edu/swanson/data/healthdy.txt</a></p>
<p>Gender 1 = Male
Gender 2 = Female</p>
<p>Flexpre = Flexability at the beginning of the semester
Flexpro = Flexability at the end of the semester</p>
<p>Bawpre = Air Weight at the beginning of the semester
Bawpro = Air weight at the end of the semester</p>
<p>Bwwpre = Water weight at the beginning of the semester
Bwwpro = Water weight at the end of the semester</p>
<p>Bfppre = Body fat at the beginning of the semester
Bfppro = Body fat at the end of the semester</p>
<p>Fvcpre = Forced capacity at the beginning of the semester
Fvcpro = Forced capacity at the end of the semester</p>
<p>Metspre = Mets at the beginning of the semester
Metspro = Mets at the end of the semester</p>
<div class="section" id="supervised-learning-problem">
<h2>Supervised learning problem<a class="headerlink" href="#supervised-learning-problem" title="Permalink to this headline">Â¶</a></h2>
<p>For simplicity and ease of visualization, we will just use the first 2
indepdendent variables as fearures for predicitng gender. In practice,
the selection of approprieate features to use as predictors can be a
challenging problem that greatly affects the effectiveness of supervised
learning.</p>
<p>So the problme is: How accurately can we guess the gender of a student
from the Flexpre and Bawpre variables?</p>
<div class="section" id="visualizing-the-data">
<h3>Visualizing the data<a class="headerlink" href="#visualizing-the-data" title="Permalink to this headline">Â¶</a></h3>
<p>First let&#8217;s make a smaller dataframe containing just the variables of
interest, and make some plots.</p>
<div class="code python highlight-python"><div class="highlight"><pre>df &lt;- healthdy[,c(&quot;ID&quot;, &quot;GENDER&quot;, &quot;FLEXPRE&quot;, &quot;BAWPRE&quot;)]
df$ID &lt;- factor(df$ID)
df$GENDER &lt;- factor(df$GENDER, labels = c(&quot;Male&quot;, &quot;Female&quot;))
df$FLEXPRE &lt;- as.numeric(df$FLEXPRE)
</pre></div>
</div>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">summary</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre>      ID         GENDER       FLEXPRE          BAWPRE
0      :  2   Male  : 82   Min.   : 1.00   Min.   :35.20
2      :  2   Female:100   1st Qu.:26.00   1st Qu.:57.73
3      :  2                Median :42.00   Median :65.05
4      :  2                Mean   :38.76   Mean   :66.99
5      :  2                3rd Qu.:52.00   3rd Qu.:74.50
6      :  2                Max.   :67.00   Max.   :98.50
(Other):170
</pre></div>
</div>
<p>Let&#8217;s check the mean flexibilitiy and weights for boys and girls.</p>
<div class="code python highlight-python"><div class="highlight"><pre>with(df, aggregate(df[,3:4], by=list(Gender=GENDER), FUN=mean))
</pre></div>
</div>
<table>
<thead><tr><th></th><th scope=col>Gender</th><th scope=col>FLEXPRE</th><th scope=col>BAWPRE</th></tr></thead>
<tbody>
    <tr><th scope=row>1</th><td>Male</td><td>33.46341</td><td>75.89024</td></tr>
    <tr><th scope=row>2</th><td>Female</td><td>43.1</td><td>59.695</td></tr>
</tbody>
</table><p>On average, girls are more flexible and weigh less than boys. This is
confirmed viually.</p>
<div class="code python highlight-python"><div class="highlight"><pre>plot(df$FLEXPRE, df$BAWPRE, col=df$GENDER,
     xlab=&quot;Flexibility&quot;, ylab=&quot;Weight&quot;,
     main=&quot;Flexibility and Weight grouped by Gender&quot;)
legend(0, 100, c(&quot;Male&quot;, &quot;Female&quot;), pch=1, col=1:2)
</pre></div>
</div>
<a class="reference internal image-reference" href="_images/SupervisedLearning_11_0.png"><img alt="_images/SupervisedLearning_11_0.png" src="_images/SupervisedLearning_11_0.png" style="width: 600px;" /></a>
</div>
</div>
<div class="section" id="comments">
<h2>Comments<a class="headerlink" href="#comments" title="Permalink to this headline">Â¶</a></h2>
<p>It looks like there is a pretty good probablility that we can guess the
gender from the body weight and flexibilty alone. The k-nearest neighbor
does this guessing in a very simple fashion - Given any point in the
data set, it looks for the nearest k neighboring points, and simply uses
the majority gender among these neighbors as the guess. In the sections
below, we&#8217;ll implement a supervised learnign pipeline using k-nearest
neighbors.</p>
<div class="section" id="work">
<h3>Work!<a class="headerlink" href="#work" title="Permalink to this headline">Â¶</a></h3>
<p>Review questions to make sure you are up to speed with basic data
manipulation and plotting.</p>
<p><strong>Q1</strong>. Tabulate the median value of FLEXPRE and BAWPRE by gender.</p>
<p><strong>Q2</strong>. Tabluate the average change in weight from the beginnig to the
end of the semester by gender.</p>
<p><strong>Q3</strong>. Identify from the plot above the IDs of 3 individuals for whom
you expect k-nearest neighbors to make the wrong gender prediction.
HInt: Make a scatterplot but add the IDs as labels for each point, using
a small x-offset of 2.5 so that labels are immediately to the right of
each point.</p>
</div>
<div class="section" id="splitting-data-into-training-and-test-data-sets">
<h3>Splitting data into training and test data sets<a class="headerlink" href="#splitting-data-into-training-and-test-data-sets" title="Permalink to this headline">Â¶</a></h3>
<p>We will use 3/4 of the data to train the algorithm and 1/4 to test how
good it is. The reason for doing this is that if we train on the full
data set, the algorithm has &#8220;seen&#8221; its test points before, and hence
will seem more accurate than it really is with respect to new data
samples. &#8216;Holding out&#8221; some of the data for testing that is not used for
training the algorithm allows us to honestly evaluate the &#8220;out of
sample&#8221; error accurately.</p>
<div class="code python highlight-python"><div class="highlight"><pre>set.seed(123) # set ranodm number seed for reproducibility
size &lt;- floor(0.75 * nrow(df)) # desired size of training set
df &lt;- df[sample(nrow(df), replace = FALSE),] # shuffle rows randomly
df.train &lt;- df[1:size, ] # take first size rows of shuffled data frame as training set
df.test &lt;- df[(size+1):nrow(df), ] # take the remaining rows as the test set
x.train &lt;- df.train[,c(&quot;FLEXPRE&quot;, &quot;BAWPRE&quot;)]
y.train &lt;- df.train[,&quot;GENDER&quot;]
x.test &lt;- df.test[,c(&quot;FLEXPRE&quot;, &quot;BAWPRE&quot;)]
y.test &lt;- df.test[,&quot;GENDER&quot;]
</pre></div>
</div>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">summary</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">train</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre>      ID         GENDER      FLEXPRE          BAWPRE
2      :  2   Male  :58   Min.   : 1.00   Min.   :35.20
4      :  2   Female:78   1st Qu.:24.75   1st Qu.:57.67
5      :  2               Median :42.00   Median :64.75
7      :  2               Mean   :38.37   Mean   :66.20
8      :  2               3rd Qu.:52.00   3rd Qu.:73.42
10     :  2               Max.   :67.00   Max.   :97.00
(Other):124
</pre></div>
</div>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">summary</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">test</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre>      ID        GENDER      FLEXPRE          BAWPRE
45     : 2   Male  :24   Min.   : 3.00   Min.   :46.60
49     : 2   Female:22   1st Qu.:31.75   1st Qu.:59.33
59     : 2               Median :43.00   Median :70.50
68     : 2               Mean   :39.91   Mean   :69.34
0      : 1               3rd Qu.:49.75   3rd Qu.:80.10
1      : 1               Max.   :65.00   Max.   :98.50
(Other):36
</pre></div>
</div>
</div>
<div class="section" id="train-knn-on-training-set">
<h3>Train knn on training set<a class="headerlink" href="#train-knn-on-training-set" title="Permalink to this headline">Â¶</a></h3>
<div class="code python highlight-python"><div class="highlight"><pre>library(class)
y.pred &lt;- knn(x.train, x.test, cl=y.train, k=3)
</pre></div>
</div>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">y</span><span class="o">.</span><span class="n">pred</span>
</pre></div>
</div>
<ol class=list-inline>
    <li>Male</li>
    <li>Male</li>
    <li>Female</li>
    <li>Female</li>
    <li>Male</li>
    <li>Female</li>
    <li>Female</li>
    <li>Male</li>
    <li>Male</li>
    <li>Male</li>
    <li>Male</li>
    <li>Female</li>
    <li>Female</li>
    <li>Male</li>
    <li>Male</li>
    <li>Female</li>
    <li>Male</li>
    <li>Male</li>
    <li>Male</li>
    <li>Female</li>
    <li>Female</li>
    <li>Male</li>
    <li>Female</li>
    <li>Female</li>
    <li>Female</li>
    <li>Female</li>
    <li>Male</li>
    <li>Female</li>
    <li>Female</li>
    <li>Female</li>
    <li>Male</li>
    <li>Male</li>
    <li>Female</li>
    <li>Female</li>
    <li>Male</li>
    <li>Female</li>
    <li>Female</li>
    <li>Male</li>
    <li>Female</li>
    <li>Male</li>
    <li>Female</li>
    <li>Female</li>
    <li>Male</li>
    <li>Male</li>
    <li>Male</li>
    <li>Male</li>
</ol></div>
<div class="section" id="evaluate-the-model">
<h3>Evaluate the model<a class="headerlink" href="#evaluate-the-model" title="Permalink to this headline">Â¶</a></h3>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">table</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">pred</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">test</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre>        y.test
y.pred   Male Female
  Male     21      2
  Female    3     20
</pre></div>
</div>
</div>
</div>
<div class="section" id="who-was-predicted-wrongly">
<h2>Who was predicted wrongly?<a class="headerlink" href="#who-was-predicted-wrongly" title="Permalink to this headline">Â¶</a></h2>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">misses</span> <span class="o">&lt;-</span> <span class="n">y</span><span class="o">.</span><span class="n">pred</span> <span class="o">!=</span> <span class="n">y</span><span class="o">.</span><span class="n">test</span>
</pre></div>
</div>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">df</span><span class="o">.</span><span class="n">test</span><span class="p">[</span><span class="n">misses</span><span class="p">,]</span>
</pre></div>
</div>
<table>
<thead><tr><th></th><th scope=col>ID</th><th scope=col>GENDER</th><th scope=col>FLEXPRE</th><th scope=col>BAWPRE</th></tr></thead>
<tbody>
    <tr><th scope=row>65</th><td>65</td><td>Male</td><td>29</td><td>68.7</td></tr>
    <tr><th scope=row>77</th><td>77</td><td>Male</td><td>36</td><td>61.4</td></tr>
    <tr><th scope=row>149</th><td>66</td><td>Female</td><td>6</td><td>90.8</td></tr>
    <tr><th scope=row>21</th><td>21</td><td>Male</td><td>52</td><td>61.7</td></tr>
    <tr><th scope=row>147</th><td>64</td><td>Female</td><td>49</td><td>77</td></tr>
</tbody>
</table><div class="code python highlight-python"><div class="highlight"><pre>plot(df.test$FLEXPRE, df.test$BAWPRE, col=df.test$GENDER,
     xlab=&quot;Flexibility&quot;, ylab=&quot;Weight&quot;,
     main=&quot;Flexibility and Weight grouped by Gender&quot;)
points(df.test$FLEXPRE[misses], df.test$BAWPRE[misses], col=&quot;blue&quot;, cex=2)

legend(0, 100, c(&quot;Male&quot;, &quot;Female&quot;), pch=1, col=1:2)
</pre></div>
</div>
<a class="reference internal image-reference" href="_images/SupervisedLearning_32_0.png"><img alt="_images/SupervisedLearning_32_0.png" src="_images/SupervisedLearning_32_0.png" style="width: 600px;" /></a>
<div class="section" id="id1">
<h3>Work!<a class="headerlink" href="#id1" title="Permalink to this headline">Â¶</a></h3>
<p>Repeat the analysis using the Bfppre and Fvcpre variables as predictors
instead. Do you get better or worse predictions?</p>
<p><strong>Q!</strong>. Extract the relevant variables into a new data frame.</p>
<p><strong>Q2</strong>. Visualize Bfppre and Fvcpre grouped by gender.</p>
<p><strong>Q3</strong>. Split the data into training and test data sets using a 2/3, 1/3
ratio.</p>
<p><strong>Q4</strong>. Find the predictions make by knn with 5 neighbors.</p>
<p><strong>Q5</strong>.. Make a table of true positives, false positives, true negatives
and false negatives. Calculate</p>
<ol class="arabic simple">
<li>accuracy</li>
<li>sensitivity</li>
<li>specificity</li>
<li>possitive predicrvie value</li>
<li>negative predictive value</li>
<li>f-score (harmonic mean of senistivity and specificity)</li>
</ol>
<p>Look up definitions in Wikipedia if you don&#8217;t know what these mean.</p>
<p><strong>Q6</strong> Make a plot to identify mis-classified subjects if any.</p>
</div>
<div class="section" id="cross-validation">
<h3>Cross-validation<a class="headerlink" href="#cross-validation" title="Permalink to this headline">Â¶</a></h3>
<p>Splitting into training and test data set is all well and good, but when
the amound data we have is small, it is wastful to have 1/4 or 1/3 as
&#8220;hold out&#8221; test data that is not used to train the algorithm. An
alternaitve is to perform cross-validation, in which we split the data
into k equal groups and cycle through all possible combinatinos of k-1
training and 1 test group. For example, if we split the data into 4
groups (&#8220;4-fold cross-validation&#8221;), we would do</p>
<ul class="simple">
<li>Train on 1,2,3 and Test on 4</li>
<li>Train on 1,2,4 and Test on 3</li>
<li>Train on 1,3,4 and Test on 2</li>
<li>Train on 2,3,4 and Test on 1</li>
</ul>
<p>then finally sum the test results to evalate the algorithm&#8217;s
performance. The limiting example where we split into as many n groups
(where n is the number of data poits) and test on only 1 data point each
time is known as Leave-One-Out-Cross-Validation (LOOCV).</p>
</div>
</div>
<div class="section" id="loocv">
<h2>LOOCV<a class="headerlink" href="#loocv" title="Permalink to this headline">Â¶</a></h2>
<p>We will use a simple (inefficient) loop version of the algorithm that
should be quite easy to understand.</p>
<p>First, we will recreat the data set in case you overwrote the variables
in the exercises.</p>
<div class="code python highlight-python"><div class="highlight"><pre>df &lt;- healthdy[,c(&quot;ID&quot;, &quot;GENDER&quot;, &quot;FLEXPRE&quot;, &quot;BAWPRE&quot;)]
df$ID &lt;- factor(df$ID)
df$GENDER &lt;- factor(df$GENDER, labels = c(&quot;Male&quot;, &quot;Female&quot;))
df$FLEXPRE &lt;- as.numeric(df$FLEXPRE)
</pre></div>
</div>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">summary</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre>      ID         GENDER       FLEXPRE          BAWPRE
0      :  2   Male  : 82   Min.   : 1.00   Min.   :35.20
2      :  2   Female:100   1st Qu.:26.00   1st Qu.:57.73
3      :  2                Median :42.00   Median :65.05
4      :  2                Mean   :38.76   Mean   :66.99
5      :  2                3rd Qu.:52.00   3rd Qu.:74.50
6      :  2                Max.   :67.00   Max.   :98.50
(Other):170
</pre></div>
</div>
<div class="code python highlight-python"><div class="highlight"><pre>y.test &lt;- df[,&quot;GENDER&quot;]
y.pred &lt;- y.test # we will overwirite the entries in the loop
for (i in 1:nrow(df)) {
    x.test &lt;- df[i, c(&quot;FLEXPRE&quot;, &quot;BAWPRE&quot;)]
    x.train &lt;- df[-i, c(&quot;FLEXPRE&quot;, &quot;BAWPRE&quot;)] # the minus menas keep all rows except i
    y.train &lt;- df[-i, &quot;GENDER&quot;]
    y.pred[i] &lt;- knn(x.train, x.test, cl=y.train, k=3)
}
</pre></div>
</div>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">table</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">pred</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">test</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre>        y.test
y.pred   Male Female
  Male     62     18
  Female   20     82
</pre></div>
</div>
<div class="code python highlight-python"><div class="highlight"><pre>misses &lt;- y.test != y.pred

plot(df$FLEXPRE, df$BAWPRE, col=df$GENDER,
     xlab=&quot;Flexibility&quot;, ylab=&quot;Weight&quot;,
     main=&quot;Flexibility and Weight grouped by Gender&quot;)
points(df$FLEXPRE[misses], df$BAWPRE[misses], col=&quot;blue&quot;, cex=2)

legend(0, 100, c(&quot;Male&quot;, &quot;Female&quot;), pch=1, col=1:2)
</pre></div>
</div>
<a class="reference internal image-reference" href="_images/SupervisedLearning_54_0.png"><img alt="_images/SupervisedLearning_54_0.png" src="_images/SupervisedLearning_54_0.png" style="width: 600px;" /></a>
<div class="section" id="id2">
<h3>Work!<a class="headerlink" href="#id2" title="Permalink to this headline">Â¶</a></h3>
<p><strong>Q1</strong>. Increase the number of neighbors to 7. Does it improve the
reuslts? Whatt are the tradeoff of increasing or decraesaing the number
of neighbors?</p>
<p><strong>Q2</strong>. Implement 5-fold cross-validation for the FLEXPRE and BAWPRE
variables. Tablutate the hits and misses and make a plot as in the
previous examples.</p>
</div>
<div class="section" id="supervised-learning-continued-what-could-go-wrong">
<h3>Supervised Learning Continued - What Could Go Wrong?<a class="headerlink" href="#supervised-learning-continued-what-could-go-wrong" title="Permalink to this headline">Â¶</a></h3>
<p>In this lab, we will demonstrate some common pitfalls that may be
encountered in performing a supervised learning analysis. To this end,
we will simulate data under the null (meaning, we will simulate no
relationship between outcome and independent variables) to observe
situations where we may commit type I error.</p>
<div class="code python highlight-python"><div class="highlight"><pre>## Supervised

# Simulate noisy data matrix (EXPRS)
set.seed(123)
# We&#39;ll use 2 groups of 20 subjects - think 20 cases and 20 controls
n=20
# Simulate 1000 genes
m=1000

# randomly generate a matrix of &#39;expression levels&#39; -- any continuous variable we may be interested in
EXPRS=matrix(rnorm(2*n*m),2*n,m)

# Just naming rows and columns
rownames(EXPRS)=paste(&quot;patient&quot;,1:(2*n),sep=&quot;&quot;)
colnames(EXPRS)=paste(&quot;gene exp&quot;,1:m,sep=&quot;&quot;)

# The group labels are assigned arbitrarily - i.e. we are just randomly assigning
#                case/control status with no reference to gene expression
grp=rep(0:1,c(n,n))
</pre></div>
</div>
<div class="code python highlight-python"><div class="highlight"><pre><span class="c">#Pick the top 10 features based on the</span>
<span class="c">#two-sample $t$-test</span>

<span class="c"># load the library &#39;genefilter&#39; - part of the Bioconductor suite</span>
<span class="n">library</span><span class="p">(</span><span class="n">genefilter</span><span class="p">)</span>

<span class="c"># rowttests is a genefilter function that performs a student t test on rows.</span>

<span class="n">ttest</span><span class="o">.</span><span class="n">data</span><span class="o">=</span><span class="n">rowttests</span><span class="p">(</span><span class="n">t</span><span class="p">(</span><span class="n">EXPRS</span><span class="p">),</span> <span class="n">factor</span><span class="p">(</span><span class="n">grp</span><span class="p">))</span>
<span class="n">head</span><span class="p">(</span><span class="n">ttest</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<table>
<thead><tr><th></th><th scope=col>statistic</th><th scope=col>dm</th><th scope=col>p.value</th></tr></thead>
<tbody>
    <tr><th scope=row>gene exp1</th><td>0.6746243</td><td>0.192881</td><td>0.5039985</td></tr>
    <tr><th scope=row>gene exp2</th><td>0.7417175</td><td>0.2264023</td><td>0.4628184</td></tr>
    <tr><th scope=row>gene exp3</th><td>3.025423</td><td>0.7344752</td><td>0.004436959</td></tr>
    <tr><th scope=row>gene exp4</th><td>0.4030939</td><td>0.1349871</td><td>0.6891382</td></tr>
    <tr><th scope=row>gene exp5</th><td>0.9545301</td><td>0.3004477</td><td>0.3458485</td></tr>
    <tr><th scope=row>gene exp6</th><td>0.3305064</td><td>0.09782354</td><td>0.7428327</td></tr>
</tbody>
</table><div class="code python highlight-python"><div class="highlight"><pre># Extract the absolute value of the statistic
stats=abs(ttest.data$statistic)

# &#39;order&#39; will return the indices of ascending values of it&#39;s argument
ii=order(-stats)

#Filter out all genes (i.e. columns of the matrix) except the top 10 rated by stats

TOPEXPRS=EXPRS[, ii[1:10]]
dim(TOPEXPRS)
</pre></div>
</div>
<ol class=list-inline>
    <li>40</li>
    <li>10</li>
</ol><p>Now we will perform a 3-nearest-neighbor clustering, just like we did
with the health dynamics class data.</p>
<div class="code python highlight-python"><div class="highlight"><pre>plot(TOPEXPRS, col=grp+1,
      main=&quot;Gene Expression&quot;)
legend(-2, 2, c(&quot;Case&quot;, &quot;Control&quot;), pch=1, col=1:2)
</pre></div>
</div>
<a class="reference internal image-reference" href="_images/SupervisedLearningWhatCouldGoWrong_6_0.png"><img alt="_images/SupervisedLearningWhatCouldGoWrong_6_0.png" src="_images/SupervisedLearningWhatCouldGoWrong_6_0.png" style="width: 600px;" /></a>
<div class="code python highlight-python"><div class="highlight"><pre># Fit 3-NN
library(class)
mod0=knn(train=TOPEXPRS,test=TOPEXPRS,cl=grp,k=3)
print(mod0)

# Error Resubstituion
table(mod0,grp)
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre> [1] 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[39] 1 1
Levels: 0 1
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre>    grp
mod0  0  1
   0 17  0
   1  3 20
</pre></div>
</div>
<div class="code python highlight-python"><div class="highlight"><pre><span class="c"># Naive CV</span>
<span class="n">mod1</span><span class="o">=</span><span class="n">knn</span><span class="o">.</span><span class="n">cv</span><span class="p">(</span><span class="n">TOPEXPRS</span><span class="p">,</span><span class="n">grp</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">table</span><span class="p">(</span><span class="n">mod1</span><span class="p">,</span><span class="n">grp</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre>    grp
mod1  0  1
   0 16  0
   1  4 20
</pre></div>
</div>
<p>This looks like differential gene expression. We can accurately predict
case-control status, based on gene expression. But, we haven&#8217;t
cross-validated. And we have only 40 subjects and have looked at 1000
genes! Let&#8217;s do it the right way now. This is like tossing a coin 40
times, and repeating that 1000 times. We <em>will</em> see some very long
strings of heads and tails in some replicates - just by chance!</p>
<div class="code python highlight-python"><div class="highlight"><pre># Oh! Super fancy code! I&#39;ll rewrite if there is time. Otherwise, we need to skip through.

# Proper CV
top.features=function(EXP,resp,test,fsnum)
  {
    top.features.i=function(i,EXP,resp,test,fsnum)
      {
        stats=abs(mt.teststat(EXP[,-i],resp[-i],test=test))
        ii=order(-stats)[1:fsnum]
        rownames(EXP)[ii]
      }
    sapply(1:ncol(EXP),top.features.i,EXP=EXP,resp=resp,test=test,fsnum=fsnum)
  }
</pre></div>
</div>
<div class="code python highlight-python"><div class="highlight"><pre># This function evaluates the knn

knn.loocv=function(EXP,resp,test,k,fsnum,tabulate=FALSE,permute=FALSE)
  {
    if(permute)
      resp=sample(resp)
    topfeat=top.features(EXP,resp,test,fsnum)
    pids=rownames(EXP)
    EXP=t(EXP)
    colnames(EXP)=as.character(pids)
    knn.loocv.i=function(i,EXP,resp,k,topfeat)
      {
        ii=topfeat[,i]
        mod=knn(train=EXP[-i,ii],test=EXP[i,ii],cl=resp[-i],k=k)[1]
      }
    out=sapply(1:nrow(EXP),knn.loocv.i,EXP=EXP,resp=resp,k=k,topfeat=topfeat)
    if(tabulate)
      out=ftable(pred=out,obs=resp)
    return(out)
}
</pre></div>
</div>
<div class="code python highlight-python"><div class="highlight"><pre>library(multtest)
knn.loocv(t(EXPRS),as.integer(grp),&quot;t.equalvar&quot;,3,10,TRUE)
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre>Loading required package: Biobase
Loading required package: BiocGenerics
Loading required package: parallel

Attaching package: âBiocGenericsâ

The following objects are masked from âpackage:parallelâ:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, parApply, parCapply, parLapply,
    parLapplyLB, parRapply, parSapply, parSapplyLB

The following object is masked from âpackage:statsâ:

    xtabs

The following objects are masked from âpackage:baseâ:

    anyDuplicated, append, as.data.frame, as.vector, cbind, colnames,
    do.call, duplicated, eval, evalq, Filter, Find, get, intersect,
    is.unsorted, lapply, Map, mapply, match, mget, order, paste, pmax,
    pmax.int, pmin, pmin.int, Position, rank, rbind, Reduce, rep.int,
    rownames, sapply, setdiff, sort, table, tapply, union, unique,
    unlist

Welcome to Bioconductor

    Vignettes contain introductory material; view with
    &#39;browseVignettes()&#39;. To cite Bioconductor, see
    &#39;citation(&quot;Biobase&quot;)&#39;, and for packages &#39;citation(&quot;pkgname&quot;)&#39;.
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre>     obs  0  1
pred
0         7  7
1        13 13
</pre></div>
</div>
<p>Well, now that looks right! We are no longer fitting noise. What&#8217;s the
difference? Everytime we perform a validation step, we need to
re-evaluate the top ten picks!</p>
</div>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright Public Domain.<br/>
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.3.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>